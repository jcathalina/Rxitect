{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8f5b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rxitect import featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456ff5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating SMILES to SELFIES: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 132040/132040 [00:11<00:00, 11330.86it/s]\n",
      "INFO:rxitect.featurization:Finished generating SEFLIES encodings...\n"
     ]
    }
   ],
   "source": [
    "enc = featurization.generate_selfies_encodings(\"../data/raw/test_smiles.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028c9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    content = open('logfile.dat', 'w')\n",
    "    content.close()\n",
    "    content = open('results.dat', 'w')\n",
    "    content.close()\n",
    "\n",
    "    if os.path.exists(\"settings.yml\"):\n",
    "        settings = yaml.safe_load(open(\"settings.yml\", \"r\"))\n",
    "    else:\n",
    "        print(\"Expected a file settings.yml but didn't find it.\")\n",
    "        return\n",
    "\n",
    "    print('--> Acquiring data...')\n",
    "    type_of_encoding = settings['data']['type_of_encoding']\n",
    "    file_name_smiles = settings['data']['smiles_file']\n",
    "\n",
    "    print('Finished acquiring data.')\n",
    "\n",
    "    if type_of_encoding == 0:\n",
    "        print('Representation: SMILES')\n",
    "        _, _, _, encoding_list, encoding_alphabet, largest_molecule_len = \\\n",
    "            get_selfie_and_smiles_encodings_for_dataset(file_name_smiles)\n",
    "\n",
    "        print('--> Creating one-hot encoding...')\n",
    "        data = multiple_smile_to_hot(encoding_list, largest_molecule_len,\n",
    "                                     encoding_alphabet)\n",
    "        print('Finished creating one-hot encoding.')\n",
    "\n",
    "    elif type_of_encoding == 1:\n",
    "        print('Representation: SELFIES')\n",
    "        encoding_list, encoding_alphabet, largest_molecule_len, _, _, _ = \\\n",
    "            get_selfie_and_smiles_encodings_for_dataset(file_name_smiles)\n",
    "\n",
    "        print('--> Creating one-hot encoding...')\n",
    "        data = multiple_selfies_to_hot(encoding_list, largest_molecule_len,\n",
    "                                       encoding_alphabet)\n",
    "        print('Finished creating one-hot encoding.')\n",
    "\n",
    "    else:\n",
    "        print(\"type_of_encoding not in {0, 1}.\")\n",
    "        return\n",
    "\n",
    "    len_max_molec = data.shape[1]\n",
    "    len_alphabet = data.shape[2]\n",
    "    len_max_mol_one_hot = len_max_molec * len_alphabet\n",
    "\n",
    "    print(' ')\n",
    "    print(f\"Alphabet has {len_alphabet} letters, \"\n",
    "          f\"largest molecule is {len_max_molec} letters.\")\n",
    "\n",
    "    data_parameters = settings['data']\n",
    "    batch_size = data_parameters['batch_size']\n",
    "\n",
    "    encoder_parameter = settings['encoder']\n",
    "    decoder_parameter = settings['decoder']\n",
    "    training_parameters = settings['training']\n",
    "\n",
    "    vae_encoder = VAEEncoder(in_dimension=len_max_mol_one_hot,\n",
    "                             **encoder_parameter).to(device)\n",
    "    vae_decoder = VAEDecoder(**decoder_parameter,\n",
    "                             out_dimension=len(encoding_alphabet)).to(device)\n",
    "\n",
    "    print('*' * 15, ': -->', device)\n",
    "\n",
    "    data = torch.tensor(data, dtype=torch.float).to(device)\n",
    "\n",
    "    train_valid_test_size = [0.5, 0.5, 0.0]\n",
    "    data = data[torch.randperm(data.size()[0])]\n",
    "    idx_train_val = int(len(data) * train_valid_test_size[0])\n",
    "    idx_val_test = idx_train_val + int(len(data) * train_valid_test_size[1])\n",
    "\n",
    "    data_train = data[0:idx_train_val]\n",
    "    data_valid = data[idx_train_val:idx_val_test]\n",
    "\n",
    "    print(\"start training\")\n",
    "    train_model(**training_parameters,\n",
    "                vae_encoder=vae_encoder,\n",
    "                vae_decoder=vae_decoder,\n",
    "                batch_size=batch_size,\n",
    "                data_train=data_train,\n",
    "                data_valid=data_valid,\n",
    "                alphabet=encoding_alphabet,\n",
    "                type_of_encoding=type_of_encoding,\n",
    "                sample_len=len_max_molec)\n",
    "\n",
    "    with open('COMPLETED', 'w') as content:\n",
    "        content.write('exit code: 0')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
