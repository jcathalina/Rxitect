{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1c5c1cf-70ba-4d3c-a574-95fa2099095e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/miniconda3/envs/rxt-dev/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from rxitect.generator.models.smiles_transformer import SmilesTransformer\n",
    "from rxitect.generator.models.components.transformer_encoder import TransformerEncoder\n",
    "from rxitect.generator.datamodules.chembl_datamodule import ChemblSmilesDataModule\n",
    "from rxitect.structs.vocabulary import SmilesVocabulary\n",
    "from rxitect.generator.datamodules.components.molecule_dataset import MoleculeDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1de75b1-6a1f-419f-b40b-44bbcadd335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "chembl_path = \"../data/processed/smiles_chembl_corpus.tsv\"\n",
    "vocabulary_filepath = \"../data/processed/smiles_voc.txt\"\n",
    "dm = ChemblSmilesDataModule(data_dir, chembl_path, vocabulary_filepath=vocabulary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c9618b-bca8-4388-99e3-e47d31845815",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TransformerEncoder(85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "699da363-f98c-43e5-9c97-759876bcaafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmilesTransformer(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f8ca7bb-c9fa-459a-8f95-2b5dbfca5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = dd.read_table(\"../data/processed/smiles_chembl_corpus.tsv\").head(n=1000)\n",
    "# ds = MoleculeDataset(data=data, vocabulary=vocabulary)\n",
    "# dl = DataLoader(ds, batch_size=256, pin_memory=True)\n",
    "# test_batch = next(iter(dl))\n",
    "# test_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86790b21-96d0-4d75-a092-c78b713eeaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = model.forward(test_batch)\n",
    "# out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ac556a9-5e3a-4389-962c-13279b8e28d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.matshow(out[:,0,:].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60bdeed3-d4ff-4d84-b4a2-a285400079d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julius/miniconda3/envs/rxt-dev/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:91: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Running in fast_dev_run mode: will run a full train, val, test and prediction loop using 1 batch(es).\n",
      "`Trainer(limit_train_batches=1)` was configured so 1 batch per epoch will be used.\n",
      "`Trainer(limit_val_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_test_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=1, fast_dev_run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ada7685-3ce7-40af-b54d-08d3230efd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected float between 0 and 1 pct_start, but got 6.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rxt-dev/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:770\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rxt-dev/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m~/miniconda3/envs/rxt-dev/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:811\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    807\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    809\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    810\u001b[0m )\n\u001b[0;32m--> 811\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/rxt-dev/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1217\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n",
      "File \u001b[0;32m~/miniconda3/envs/rxt-dev/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py:72\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: pl\u001b[38;5;241m.\u001b[39mTrainer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_to_device()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rxt-dev/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py:139\u001b[0m, in \u001b[0;36mStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m\"\"\"Setup plugins for the trainer fit and creates optimizers.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    trainer: the trainer instance\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39msetup(trainer)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_precision_plugin()\n\u001b[1;32m    141\u001b[0m optimizers_to_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/rxt-dev/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py:128\u001b[0m, in \u001b[0;36mStrategy.setup_optimizers\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (TrainerFn\u001b[38;5;241m.\u001b[39mFITTING, TrainerFn\u001b[38;5;241m.\u001b[39mTUNING):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler_configs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_frequencies \u001b[38;5;241m=\u001b[39m \u001b[43m_init_optimizers_and_lr_schedulers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/rxt-dev/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py:180\u001b[0m, in \u001b[0;36m_init_optimizers_and_lr_schedulers\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m\"\"\"Calls `LightningModule.configure_optimizers` and parses and validates the output.\"\"\"\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m model\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m optim_conf \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconfigure_optimizers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m optim_conf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     rank_zero_warn(\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    185\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/rxt-dev/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1595\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1592\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1595\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1598\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/University/Thesis/rxitect/src/rxitect/generator/models/smiles_transformer.py:80\u001b[0m, in \u001b[0;36mSmilesTransformer.configure_optimizers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m     79\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmax_epochs\n\u001b[0;32m---> 80\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOneCycleLR\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m               \u001b[49m\u001b[43mtotal_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m               \u001b[49m\u001b[43mpct_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manneal_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcos\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle_momentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m               \u001b[49m\u001b[43mbase_momentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.85\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_momentum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m               \u001b[49m\u001b[43mdiv_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_div_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m: scheduler, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minterval\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m }\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [optimizer], [scheduler]\n",
      "File \u001b[0;32m~/miniconda3/envs/rxt-dev/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:1522\u001b[0m, in \u001b[0;36mOneCycleLR.__init__\u001b[0;34m(self, optimizer, max_lr, total_steps, epochs, steps_per_epoch, pct_start, anneal_strategy, cycle_momentum, base_momentum, max_momentum, div_factor, final_div_factor, three_phase, last_epoch, verbose)\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;66;03m# Validate pct_start\u001b[39;00m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pct_start \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m pct_start \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pct_start, \u001b[38;5;28mfloat\u001b[39m):\n\u001b[0;32m-> 1522\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected float between 0 and 1 pct_start, but got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pct_start))\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;66;03m# Validate anneal_strategy\u001b[39;00m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m anneal_strategy \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected float between 0 and 1 pct_start, but got 6.0"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f555bc77-636c-4c26-a10a-c71c4692617e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.train_dataloader().__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7585172-9725-44ae-ab4a-0f63eb21494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e871d904-0118-441f-962c-d3ebfbf74a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "70_000 / 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afa9ed8-0c0e-46d8-9972-b777d30a70f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.max_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e0c28fa-7492-44ea-aedf-d920860cc8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "964992cc-a00d-41ee-a94c-09327260be9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pytorch_lightning.callbacks.lr_monitor.LearningRateMonitor"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pytorch_lightning.callbacks.LearningRateMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f53d233-55ca-4e2b-94ce-e3e8f4e30794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
