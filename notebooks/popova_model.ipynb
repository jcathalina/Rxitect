{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "056f7078-d5a7-4679-a1a6-dc2ae0f6d8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import trange\n",
    "\n",
    "from rxitect.models.pchembl_val_predictor import PChEMBLValueRegressor, get_tokens, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e25a8741-fd42-4d46-87a2-28635cd99306",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/processed/ligand_CHEMBL240_train_splityear=2015.csv\")\n",
    "df_test = pd.read_csv(\"../data/processed/ligand_CHEMBL240_test_splityear=2015.csv\")\n",
    "\n",
    "# df_full = pd.concat([df_train, df_test])\n",
    "smiles = df_train.smiles\n",
    "labels = df_train.pchembl_value.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "539e9019-445f-44e1-a643-c51b68f090a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, _, _ = get_tokens(smiles)\n",
    "tokens = ''.join(tokens) + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94c7e68a-4fac-4462-8c3e-74b79dc8e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = PChEMBLValueRegressor(tokens, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfc066fd-7268-4e3e-b456-59801f6a9444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PChEMBLValueRegressor(\n",
       "  (criterion): MSELoss()\n",
       "  (embedding): Embedding(\n",
       "    (embedding): Embedding(42, 128, padding_idx=41)\n",
       "  )\n",
       "  (encoder): LSTMEncoder(\n",
       "    (rnn): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.8)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (input_layer): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (out_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b9442e9-3cd1-4467-9b56-757d2f6733f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2tensor(seqs, tokens, flip=True):\n",
    "    tensor = np.zeros((len(seqs), len(seqs[0])))\n",
    "    for i in trange(len(seqs), desc=\"Transforming sequences to tensors\"):\n",
    "        for j in range(len(seqs[i])):\n",
    "            if seqs[i][j] in tokens:\n",
    "                tensor[i, j] = tokens.index(seqs[i][j])\n",
    "            else:\n",
    "                tokens = tokens + seqs[i][j]\n",
    "                tensor[i, j] = tokens.index(seqs[i][j])\n",
    "    if flip:\n",
    "        tensor = np.flip(tensor, axis=1).copy()\n",
    "    return tensor, tokens\n",
    "\n",
    "\n",
    "def pad_sequences(seqs, max_length=None, pad_symbol=' '):\n",
    "    if max_length is None:\n",
    "        max_length = -1\n",
    "        for seq in seqs:\n",
    "            max_length = max(max_length, len(seq))\n",
    "    lengths = []\n",
    "    for i in trange(len(seqs), desc=\"Padding sequences\"):\n",
    "        cur_len = len(seqs[i])\n",
    "        lengths.append(cur_len)\n",
    "        seqs[i] = seqs[i] + pad_symbol * (max_length - cur_len)\n",
    "    return seqs, lengths\n",
    "\n",
    "\n",
    "def process_smiles(smiles,\n",
    "                   sanitized=True,\n",
    "                   target=None,\n",
    "                   augment=False,\n",
    "                   pad=True,\n",
    "                   tokenize=True,\n",
    "                   tokens=None,\n",
    "                   flip=False,\n",
    "                   allowed_tokens=None):\n",
    "    if not sanitized:\n",
    "        # clean_smiles, clean_idx = sanitize_smiles(smiles, allowed_tokens=allowed_tokens)\n",
    "        # clean_smiles = [clean_smiles[i] for i in clean_idx]\n",
    "        # if target is not None:\n",
    "        #     target = target[clean_idx]\n",
    "        pass\n",
    "    else:\n",
    "        clean_smiles = smiles\n",
    "\n",
    "    length = None\n",
    "    if augment and target is not None:\n",
    "        # clean_smiles, target = augment_smiles(clean_smiles, target)\n",
    "        pass\n",
    "    if pad:\n",
    "        clean_smiles, length = pad_sequences(clean_smiles)\n",
    "    tokens, token2idx, num_tokens = get_tokens(clean_smiles, tokens)\n",
    "    if tokenize:\n",
    "        clean_smiles, tokens = seq2tensor(clean_smiles, tokens, flip)\n",
    "\n",
    "    return clean_smiles, target, length, tokens, token2idx, num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd7920ea-01de-4439-a987-c97d72100d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding sequences: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 114880.96it/s]\n",
      "Transforming sequences to tensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 706.84it/s]\n"
     ]
    }
   ],
   "source": [
    "smi = process_smiles(smiles[:100], sanitized=True, target=labels, augment=False, pad=True,\n",
    "            tokenize=True, tokens=tokens, flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "471715f2-ad4a-43b4-93fd-20a5a5df7cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 407)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smi[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0105f225-6ee8-4821-9d44-4386ad8d8cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmilesDataset(Dataset):\n",
    "    def __init__(self, smiles, labels, tokens=None, tokenize=True, sanitized=True, return_smiles=False):\n",
    "        super(SmilesDataset, self).__init__()\n",
    "        self.tokenize = tokenize\n",
    "        self.return_smiles = return_smiles\n",
    "        self.data, self.target, self.length, self.tokens, self.token2idx, self.num_tokens = process_smiles(\n",
    "            smiles, sanitized=True, target=labels, augment=False, pad=True,\n",
    "            tokenize=tokenize, tokens=tokens, flip=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = {}\n",
    "        if self.return_smiles:\n",
    "            sample['object'] = np.array([ord(self.tokens[int(i)]) for i in self.data[index]])\n",
    "        sample['tokenized_smiles'] = self.data[index]\n",
    "        sample['length'] = self.length[index]\n",
    "        if self.target is not None:\n",
    "            sample['labels'] = self.target[index]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e44f7b8-cae8-42b6-98f9-afe90c0d7d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding sequences:   0%|                                                                                                                 | 0/7223 [00:00<?, ?it/s]/tmp/ipykernel_2426/3301636560.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  seqs[i] = seqs[i] + pad_symbol * (max_length - cur_len)\n",
      "Padding sequences: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 7223/7223 [02:26<00:00, 49.20it/s]\n",
      "Transforming sequences to tensors: 100%|█████████████████████████████████████████████████████████████████████████████████████| 7223/7223 [00:09<00:00, 726.18it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = SmilesDataset(smiles, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f0b287c-8220-4f98-b12c-ee174849a0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data,\n",
    "                         batch_size=128,\n",
    "                         shuffle=True,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True,\n",
    "                         sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7165af0-56bf-48a9-96d5-6da122b7c82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=26, accelerator='gpu', devices=1, log_every_n_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3503f5aa-c52e-4a92-9690-957c91db1776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type        | Params\n",
      "------------------------------------------\n",
      "0 | criterion | MSELoss     | 0     \n",
      "1 | embedding | Embedding   | 5.4 K \n",
      "2 | encoder   | LSTMEncoder | 264 K \n",
      "3 | mlp       | MLP         | 16.6 K\n",
      "------------------------------------------\n",
      "286 K     Trainable params\n",
      "0         Non-trainable params\n",
      "286 K     Total params\n",
      "1.145     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 57/57 [00:03<00:00, 15.53it/s, loss=1.06, v_num=3]\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(reg, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a434fc4e-4b65-4edc-842f-191d8b99ca60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PChEMBLValueRegressor(\n",
       "  (criterion): MSELoss()\n",
       "  (embedding): Embedding(\n",
       "    (embedding): Embedding(42, 128, padding_idx=41)\n",
       "  )\n",
       "  (encoder): LSTMEncoder(\n",
       "    (rnn): LSTM(128, 128, num_layers=2, batch_first=True, dropout=0.8)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (input_layer): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (out_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a593a7fb-0162-4fdd-b6e1-e5179380b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor(train_data[0]['tokenized_smiles']), torch.tensor(train_data[0]['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03895bf5-e839-4fce-b09b-737d17610496",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inp \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtokenized_smiles\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlength\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "inp = np.array([train_data[0]['tokenized_smiles'], train_data[0]['length']], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6183c0e9-7d08-41f8-b95f-402d5254c0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_data[0]['length']).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57979826-b722-495f-a488-f1273e749481",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got list)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got list)"
     ]
    }
   ],
   "source": [
    "torch.from_numpy(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6274a838-b635-464e-a253-96ba8ac5e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.from_numpy(train_data[7:8]['tokenized_smiles'].astype('float32'))\n",
    "b = torch.tensor(train_data[7:8]['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f6e6bfdc-ead2-4911-871c-9f94f9f39232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.4522]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d5ffb56e-15ca-426d-988f-445c25448b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6.040\n",
       "1    3.990\n",
       "2    6.465\n",
       "Name: pchembl_value, dtype: float32"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:3]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ff33de5-3110-4cf9-b4ee-c4021c160efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.3020287"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:]['labels'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "583226f7-a10e-4609-bd0d-201c4eea31f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokenized_smiles': array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.,  0.,  0.,  0.,  0.,  0.,  8., 21., 21.,  3.,  9., 35.,\n",
       "         35., 35., 35., 35.,  9., 35.,  3.,  9., 35., 35., 35., 35., 35.,\n",
       "          9., 35.,  2., 21.,  2., 26., 21., 21.,  8., 26., 21.,  3., 27.,\n",
       "          2., 21., 21., 27.,  8., 35., 35., 35., 35., 35.,  8., 35.,  3.,\n",
       "          8., 35., 35., 35., 35., 35.,  8., 35., 21., 21.,  2., 21., 17.,\n",
       "         27.,  6., 37., 21.]]),\n",
       " 'length': [62],\n",
       " 'labels': 7    5.58\n",
       " Name: pchembl_value, dtype: float32}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[7:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c4077e-151c-4f74-ad6f-4a31edfdcc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
